### Action
- (CVPR'20) Speech2Action: Cross-modal Supervision for Action Recognition, [[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Nagrani_Speech2Action_Cross-Modal_Supervision_for_Action_Recognition_CVPR_2020_paper.pdf)
- (arXiv 2021.01) Trear: Transformer-based RGB-D Egocentric Action Recognition, [[Paper]](https://arxiv.org/pdf/2101.03904.pdf)
- (arXiv 2021.02) Relaxed Transformer Decoders for Direct Action Proposal Generation, [[Paper]](https://arxiv.org/pdf/2102.01894.pdf), [[Code]](https://github.com/MCG-NJU/RTD-Action)
- (arXiv 2021.04) TubeR: Tube-Transformer for Action Detection, [[Paper]](https://arxiv.org/pdf/2104.00969.pdf)
- (arXiv 2021.04) Few-Shot Transformation of Common Actions into Time and Space, [[Paper]](https://arxiv.org/pdf/2104.02439.pdf)
- (arXiv 2021.05) Temporal Action Proposal Generation with Transformers, [[Paper]](https://arxiv.org/pdf/2105.12043.pdf)
- (arXiv 2021.06) End-to-end Temporal Action Detection with Transformer, [[Paper]](https://arxiv.org/pdf/2106.10271.pdf), [[Code]](https://github.com/xlliu7/TadTR)
- (arXiv 2021.06) OadTR: Online Action Detection with Transformers, [[Paper]](https://arxiv.org/pdf/2106.11149.pdf), [[Code]](https://github.com/wangxiang1230/OadTR)
- (arXiv 2021.07) Action Transformer: A Self-Attention Model for Short-Time Human Action Recognition, [[Paper]](https://arxiv.org/pdf/2107.00606.pdf)
- (arXiv 2021.07) VideoLightFormer: Lightweight Action Recognition using Transformers, [[Paper]](https://arxiv.org/pdf/2107.00451.pdf)
- (arXiv 2021.07) Long Short-Term Transformer for Online Action Detection, [[Paper]](https://arxiv.org/pdf/2107.03377.pdf)
- (arXiv 2021.07) STAR: Sparse Transformer-based Action Recognition, [[Paper]](https://arxiv.org/pdf/2107.07089.pdf), [[Code]](https://github.com/imj2185/STAR)
- (arXiv 2021.08) Shifted Chunk Transformer for Spatio-Temporal Representational Learning, [[Paper]](https://arxiv.org/pdf/2108.11575.pdf)
- (arXiv 2021.08) GroupFormer: Group Activity Recognition with Clustered Spatial-Temporal Transformer, [[Paper]](https://arxiv.org/pdf/2108.12630.pdf), [[Code]](https://github.com/xueyee/GroupFormer)
- (arXiv 2021.09) GCsT: Graph Convolutional Skeleton Transformer for Action Recognition, [[Paper]](https://arxiv.org/pdf/2109.02860.pdf), [[Code]](https://github.com/xueyee/GroupFormer)
- (arXiv 2021.10) Lightweight Transformer in Federated Setting for Human Activity Recognition, [[Paper]](https://arxiv.org/pdf/2110.00244.pdf)
- (arXiv 2021.10) ASFormer: Transformer for Action Segmentation, [[Paper]](https://arxiv.org/pdf/2110.08568.pdf), [[Code]](https://github.com/ChinaYi/ASFormer)
- (arXiv 2021.10) Few-Shot Temporal Action Localization with Query Adaptive Transformer, [[Paper]](https://arxiv.org/pdf/2110.10552.pdf), [[Code]](https://github.com/sauradip/fewshotQAT)
- (arXiv 2021.10) IIP-Transformer: Intra-Inter-Part Transformer for Skeleton-Based Action Recognition, [[Paper]](https://arxiv.org/pdf/2110.13385.pdf), [[Code]](https://github.com/qtwang0035/IIP-Transformer)
- (arXiv 2021.11) Evaluating Transformers for Lightweight Action Recognition, [[Paper]](https://arxiv.org/pdf/2111.09641.pdf)
- (arXiv 2021.12) MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection, [[Paper]](https://arxiv.org/pdf/2112.03902.pdf)
- (arXiv 2021.12) Co-training Transformer with Videos and Images Improves Action Recognition, [[Paper]](https://arxiv.org/pdf/2112.07175.pdf)
- (arXiv 2021.12) Temporal Transformer Networks with Self-Supervision for Action Recognition, [[Paper]](https://arxiv.org/pdf/2112.07338.pdf)
- (arXiv 2022.01) Spatio-Temporal Tuples Transformer for Skeleton-Based Action Recognition, [[Paper]](https://arxiv.org/pdf/2201.02849.pdf), [[Code]](https://github.com/heleiqiu/STTFormer)
- (arXiv 2022.01) Transformers in Action:Weakly Supervised Action Segmentation, [[Paper]](https://arxiv.org/pdf/2201.05675.pdf)
- (arXiv 2022.02) ActionFormer: Localizing Moments of Actions with Transformers, [[Paper]](https://arxiv.org/pdf/2202.07925.pdf), [[Code]](https://github.com/happyharrycn/actionformer_release)
- (arXiv 2022.03) Multi-View Fusion Transformer for Sensor-Based Human Activity Recognition, [[Paper]](https://arxiv.org/pdf/2202.12949.pdf)
- (arXiv 2022.03) TransDARC: Transformer-based Driver Activity Recognition with Latent Space Feature Calibration, [[Paper]](https://arxiv.org/pdf/2203.00927.pdf), [[Code]](https://github.com/KPeng9510/TransDARC)
- (arXiv 2022.03) Zero-Shot Action Recognition with Transformer-based Video Semantic Embedding, [[Paper]](https://arxiv.org/pdf/2203.05156.pdf)
- (arXiv 2022.03) LocATe: End-to-end Localization of Actions in 3D with Transformers, [[Paper]](https://arxiv.org/pdf/2203.10719.pdf)
- (arXiv 2022.03) DirecFormer: A Directed Attention in Transformer Approach to Robust Action Recognition, [[Paper]](https://arxiv.org/pdf/2203.10233.pdf), [[Code]](https://github.com/uark-cviu/DirecFormer)
- (arXiv 2022.03) Multi-label Transformer for Action Unit Detection, [[Paper]](https://arxiv.org/pdf/2203.12531.pdf)
- (arXiv 2022.04) Vision Transformer with Cross-attention by Temporal Shift for Efficient Action Recognition, [[Paper]](https://arxiv.org/pdf/2204.00452.pdf)
- (arXiv 2022.04) TALLFormer: Temporal Action Localization with Long-memory Transformer, [[Paper]](https://arxiv.org/pdf/2204.01680.pdf), [[Code]](https://github.com/klauscc/TALLFormer)
- (arXiv 2022.04) TransRAC: Encoding Multi-scale Temporal Correlation with Transformers for Repetitive Action Counting, [[Paper]](https://arxiv.org/pdf/2204.01018.pdf), [[Code]](https://github.com/SvipRepetitionCounting/TransRAC)
- (arXiv 2022.04) Detector-Free Weakly Supervised Group Activity Recognition, [[Paper]](https://arxiv.org/pdf/2204.02139.pdf), [[Code]](https://cvlab.postech.ac.kr/research/DFWSGAR/)
- (arXiv 2022.05) Cross-modal Representation Learning for Zero-shot Action Recognition, [[Paper]](https://arxiv.org/pdf/2205.01657.pdf), [[Code]](https://github.com/microsoft/ResT)
- (arXiv 2022.05) Entity-aware and Motion-aware Transformers for Language-driven Action Localization in Videos, [[Paper]](https://arxiv.org/pdf/2205.05854.pdf), [[Code]](https://github.com/shuoyang129/EAMAT)
- (arXiv 2022.05) Cross-subject Action Unit Detection with Meta Learning and Transformer-based Relation Modeling, [[Paper]](https://arxiv.org/pdf/2205.08787.pdf)
- (arXiv 2022.05) Cross-Enhancement Transformer for Action Segmentation, [[Paper]](https://arxiv.org/pdf/2205.09445.pdf)
- (arXiv 2022.05) Efficient U-Transformer with Boundary-Aware Loss for Action Segmentation, [[Paper]](https://arxiv.org/pdf/2205.13425.pdf)
- (arXiv 2022.05) Future Transformer for Long-term Action Anticipation, [[Paper]](https://arxiv.org/pdf/2205.14022.pdf), [[Code]](http://cvlab.postech.ac.kr/research/FUTR)
- (arXiv 2022.06) One-stage Action Detection Transformer, [[Paper]](https://arxiv.org/pdf/2206.10080.pdf)
- (arXiv 2022.06) Spatial Transformer Network with Transfer Learning for Small-scale Fine-grained Skeleton-based Tai Chi Action Recognition, [[Paper]](https://arxiv.org/pdf/2206.15002.pdf)
- (arXiv 2022.07) Hunting Group Clues with Transformers for Social Group Activity Recognition, [[Paper]](https://arxiv.org/pdf/2207.05254.pdf)
- (arXiv 2022.07) Global-local Motion Transformer for Unsupervised Skeleton-based Action Learning, [[Paper]](https://arxiv.org/pdf/2207.06101.pdf),[[Code]](https://github.com/Boeun-Kim/GL-Transformer)
- (arXiv 2022.07) Entry-Flipped Transformer for Inference and Prediction of Participant Behavior, [[Paper]](https://arxiv.org/pdf/2207.06235.pdf),[[Code]](https://github.com/Boeun-Kim/GL-Transformer)
- (arXiv 2022.07) Action Quality Assessment with Temporal Parsing Transformer, [[Paper]](https://arxiv.org/pdf/2207.09270.pdf)
- (arXiv 2022.07) HTNet: Anchor-free Temporal Action Localization with Hierarchical Transformers, [[Paper]](https://arxiv.org/pdf/2207.09662.pdf)
- (arXiv 2022.07) An Efficient Spatio-Temporal Pyramid Transformer for Action Detection, [[Paper]](https://arxiv.org/pdf/2207.10448.pdf)
- (arXiv 2022.07) Action Quality Assessment using Transformers, [[Paper]](https://arxiv.org/pdf/2207.12318.pdf)
- (arXiv 2022.07) Unsupervised Domain Adaptation for Video Transformers in Action Recognition, [[Paper]](https://arxiv.org/pdf/2207.12842.pdf),[[Code]](https://github.com/vturrisi/UDAVT)
- (arXiv 2022.07) Spatiotemporal Self-attention Modeling with Temporal Patch Shift for Action Recognition, [[Paper]](https://arxiv.org/pdf/2207.13259.pdf),[[Code]](https://github.com/MartinXM/TPS)
- (arXiv 2022.08) Combined CNN Transformer Encoder for Enhanced Fine-grained Human Action Recognition, [[Paper]](https://arxiv.org/pdf/2208.01897.pdf)
- (arXiv 2022.08) ViT-ReT: Vision and Recurrent Transformer Neural Networks for Human Activity Recognition in Videos, [[Paper]](https://arxiv.org/pdf/2208.07929.pdf),[[Code]](https://github.com/JamesWensel/TranformerActivityRecognition)
- (arXiv 2022.08) Adaptive Perception Transformer for Temporal Action Localization, [[Paper]](https://arxiv.org/pdf/2208.11908.pdf),[[Code]](https://github.com/SouperO/AdaPerFormer)
- (arXiv 2022.08) A Circular Window-based Cascade Transformer for Online Action Detection, [[Paper]](https://arxiv.org/pdf/2208.14209.pdf)
- (arXiv 2022.09) Self-Supervised Multimodal Fusion Transformer for Passive Activity Recognition, [[Paper]](https://arxiv.org/pdf/2209.03765.pdf)
- (arXiv 2022.09) TASKED: Transformer-based Adversarial learning for human activity recognition using wearable sensors via Self-KnowledgE Distillation, [[Paper]](https://arxiv.org/pdf/2209.09092.pdf)
- (arXiv 2022.09) Exploring Modulated Detection Transformer as a Tool for Action Recognition in Videos, [[Paper]](https://arxiv.org/pdf/2209.10126.pdf)
- (arXiv 2022.09) Lightweight Transformers for Human Activity Recognition on Mobile Devices, [[Paper]](https://arxiv.org/pdf/2209.11750.pdf)
- (arXiv 2022.09) Multi-dataset Training of Transformers for Robust Action Recognition, [[Paper]](https://arxiv.org/pdf/2209.12362.pdf),[[Code]](https://github.com/JunweiLiang/MultiTrain)
- (arXiv 2022.10) Focal and Global Spatial-Temporal Transformer for Skeleton-based Action Recognition, [[Paper]](https://arxiv.org/pdf/2210.02693.pdf),[[Code]](https://github.com/JunweiLiang/MultiTrain)
- (arXiv 2022.10) STAR-Transformer: A Spatio-temporal Cross Attention Transformer for Human Action Recognition, [[Paper]](https://arxiv.org/pdf/2210.07503.pdf)
- (arXiv 2022.10) Transformer-based Action recognition in hand-object interacting scenarios, [[Paper]](https://arxiv.org/pdf/2210.11387.pdf)
- (arXiv 2022.10) Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation, [[Paper]](https://arxiv.org/pdf/2210.12649.pdf)
- (arXiv 2022.10) Holistic Interaction Transformer Network for Action Detection, [[Paper]](https://arxiv.org/pdf/2210.12686.pdf),[[Code]](https://github.com/joslefaure/HIT)
- (arXiv 2022.10) GliTr: Glimpse Transformers with Spatiotemporal Consistency for Online Action Prediction, [[Paper]](https://arxiv.org/pdf/2210.13605.pdf)
- (arXiv 2022.10) Hypergraph Transformer for Skeleton-based Action Recognition, [[Paper]](https://arxiv.org/pdf/2211.09590.pdf)
- (arXiv 2022.11) SVFormer: Semi-supervised Video Transformer for Action Recognition, [[Paper]](https://arxiv.org/pdf/2211.13222.pdf),[[Code]](https://github.com/ChenHsing/SVFormer)
- (arXiv 2022.11) Interaction Visual Transformer for Egocentric Action Anticipation, [[Paper]](https://arxiv.org/pdf/2211.14154.pdf),[[Code]](https://github.com/ChenHsing/SVFormer)
- (arXiv 2023.02) Transformers in Action Recognition: A Review on Temporal Modeling, [[Paper]](https://arxiv.org/pdf/2302.01921.pdf)
- (arXiv 2023.02) Video Action Recognition Collaborative Learning with Dynamics via PSO-ConvNet Transformer, [[Paper]](https://arxiv.org/pdf/2302.09187.pdf),[[Code]](https://github.com/leonlha/Video-Action-Recognition-via-PSO-ConvNet-Transformer-Collaborative-Learning-with-Dynamics)
- (arXiv 2023.02) Spatial-temporal Transformer-guided Diffusion based Data Augmentation for Efficient Skeleton-based Action Recognition, [[Paper]](https://arxiv.org/pdf/2302.13434.pdf)
- (arXiv 2023.02) Temporal Segment Transformer for Action Segmentation, [[Paper]](https://arxiv.org/pdf/2302.13074.pdf)
- (arXiv 2023.03) EgoViT: Pyramid Video Transformer for Egocentric Action Recognition, [[Paper]](https://arxiv.org/pdf/2303.08920.pdf)
- (arXiv 2023.03) Vision Transformer for Action Units Detection, [[Paper]](https://arxiv.org/pdf/2303.09917.pdf)
- (arXiv 2023.03) Group Activity Recognition using Self-supervised Approach of Spatiotemporal Transformers, [[Paper]](https://arxiv.org/pdf/2303.12149.pdf)
- (arXiv 2023.03) 3Mformer: Multi-order Multi-mode Transformer for Skeletal Action Recognition, [[Paper]](https://arxiv.org/pdf/2303.14474.pdf)
- (arXiv 2023.04) STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition, [[Paper]](https://arxiv.org/pdf/2303.18177.pdf),[[Code]](https://github.com/zgzxy001/STMT)
- (arXiv 2023.04) End-to-End Spatio-Temporal Action Localisation with Video Transformers, [[Paper]](https://arxiv.org/pdf/2304.12160.pdf)
- (arXiv 2023.05) Distilled Mid-Fusion Transformer Networks for Multi-Modal Human Activity Recognition, [[Paper]](https://arxiv.org/pdf/2305.03810.pdf)
- (arXiv 2023.05) Multi-View Multi-Scale Driver Action Recognition with Vision Transformer, [[Paper]](https://arxiv.org/pdf/2305.08877.pdf),[[Code]](https://github.com/PurdueDigitalTwin/M2DAR)
- (arXiv 2023.05) Enhancing Transformer Backbone for Egocentric Video Action Segmentation, [[Paper]](https://arxiv.org/pdf/2305.11365.pdf),[[Code]](https://www.sail-nu.com/dxformer)
- (arXiv 2023.05) A Multi-Modal Transformer Network for Action Detection, [[Paper]](https://arxiv.org/pdf/2305.19624.pdf)
- (arXiv 2023.06) Optimizing ViViT Training: Time and Memory Reduction for Action Recognition, [[Paper]](https://arxiv.org/pdf/2306.04822.pdf)
- (arXiv 2023.06) SpATr: MoCap 3D Human Action Recognition based on Spiral Auto-encoder and Transformer Network, [[Paper]](https://arxiv.org/pdf/2306.17574.pdf)
- (arXiv 2023.07) Task-Specific Alignment and Multiple Level Transformer for Few-Shot Action Recognition, [[Paper]](https://arxiv.org/pdf/2307.01985.pdf),[[Code]](https://github.com/cofly2014/tsa-mlt.git)
- (arXiv 2023.07) VS-TransGRU: A Novel Transformer-GRU-based Framework Enhanced by Visual-Semantic Fusion for Egocentric Action Anticipation, [[Paper]](https://arxiv.org/pdf/2307.03918.pdf)
- (arXiv 2023.07) Multimodal Distillation for Egocentric Action Recognition, [[Paper]](https://arxiv.org/pdf/2307.07483.pdf)
- (arXiv 2023.07) Human Action Recognition in Still Images Using ConViT, [[Paper]](https://arxiv.org/pdf/2307.08994.pdf)
- (arXiv 2023.07) MSQNet: Actor-agnostic Action Recognition with Multi-modal Query, [[Paper]](https://arxiv.org/pdf/2307.10763.pdf), [[Code]](https://github.com/mondalanindya/MSQNet)
- (arXiv 2023.07) Event-based Vision for Early Prediction of Manipulation Actions, [[Paper]](https://arxiv.org/pdf/2307.14332.pdf)
- (arXiv 2023.08) PAT: Position-Aware Transformer for Dense Multi-Label Action Detection, [[Paper]](https://arxiv.org/pdf/2308.05051.pdf)
- (arXiv 2023.08) Seeing in Flowing: Adapting CLIP for Action Recognition with Motion Prompts Learning, [[Paper]](https://arxiv.org/pdf/2308.04828.pdf)
- (arXiv 2023.08) MAiVAR-T: Multimodal Audio-image and Video Action Recognizer using Transformers, [[Paper]](https://arxiv.org/pdf/2308.03741.pdf)
- (arXiv 2023.08) Memory-and-Anticipation Transformer for Online Action Understanding, [[Paper]](https://arxiv.org/pdf/2308.07893.pdf), [[Code]](https://github.com/Echo0125/)
- (arXiv 2023.08) Self-Feedback DETR for Temporal Action Detection, [[Paper]](https://arxiv.org/pdf/2308.10570.pdf), [[Code]](https://github.com/Echo0125/)
- (arXiv 2023.08) EventTransAct: A video transformer-based framework for Event-camera based action recognition, [[Paper]](https://arxiv.org/pdf/2308.13711.pdf), [[Code]](https://tristandb8.github.io/EventTransAct_webpage/)
- (arXiv 2023.08) Topology-aware MLP for Skeleton-based Action Recognition, [[Paper]](https://arxiv.org/pdf/2308.16018.pdf), [[Code]](https://github.com/BUPTSJZhang/Ta-MLP)
- (arXiv 2023.08) Prompt-enhanced Hierarchical Transformer Elevating Cardiopulmonary Resuscitation Instruction via Temporal Action Segmentation, [[Paper]](https://arxiv.org/pdf/2308.16552.pdf)
- (arXiv 2023.09) COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action Spotting using Transformers, [[Paper]](https://arxiv.org/pdf/2309.01270.pdf), [[Code]](https://github.com/juliendenize/eztorch)
- (arXiv 2023.09) Unified Contrastive Fusion Transformer for Multimodal Human Action Recognition, [[Paper]](https://arxiv.org/pdf/2309.05032.pdf)
- (arXiv 2023.09) SkeleTR: Towrads Skeleton-based Action Recognition in the Wild, [[Paper]](https://arxiv.org/pdf/2309.11445.pdf)
- (arXiv 2023.09) Egocentric RGB+Depth Action Recognition in Industry-Like Settings, [[Paper]](https://arxiv.org/pdf/2309.13962.pdf)
- (arXiv 2023.10) POTLoc: Pseudo-Label Oriented Transformer for Point-Supervised Temporal Action Localization, [[Paper]](https://arxiv.org/pdf/2310.13585.pdf)
- (arXiv 2023.11) Distilling Knowledge from CNN-Transformer Models for Enhanced Human Action Recognition, [[Paper]](https://arxiv.org/pdf/2311.01283.pdf)
- (arXiv 2023.11) Act-VIT: A Representationally Robust Attention Architecture for Skeleton Based Action Recognition Using Vision Transformer, [[Paper]](https://arxiv.org/pdf/2311.08094.pdf)
- (arXiv 2023.11) SigFormer: Sparse Signal-Guided Transformer for Multi-Modal Human Action Segmentation, [[Paper]](https://arxiv.org/pdf/2311.17428.pdf), [[Code]](https://github.com/LIUQI-creat/SigFormer)
- (arXiv 2023.11) GeoDeformer: Geometric Deformable Transformer for Action Recognition, [[Paper]](https://arxiv.org/pdf/2311.17975.pdf)
- (arXiv 2023.12) REACT: Recognize Every Action Everywhere All At Once, [[Paper]](https://arxiv.org/pdf/2312.00188.pdf)
- (arXiv 2023.12) Adapting Short-Term Transformers for Action Detection in Untrimmed Videos, [[Paper]](https://arxiv.org/pdf/2312.00188.pdf)
- (arXiv 2023.12) STEP CATFormer: Spatial-Temporal Effective Body-Part Cross Attention Transformer for Skeleton-based Action Recognition, [[Paper]](https://arxiv.org/pdf/2312.03288.pdf),[[Code]](https://github.com/maclong01/STEP-CATFormer)
- (arXiv 2024.01) Multi-view Distillation based on Multi-modal Fusion for Few-shot Action Recognition, [[Paper]](https://arxiv.org/pdf/2401.08345.pdf),[[Code]](https://github.com/cofly2014/MDMF)
- (arXiv 2024.03) SkateFormer: Skeletal-Temporal Transformer for Human Action Recognition, [[Paper]](https://arxiv.org/pdf/2403.09508.pdf),[[Code]](https://jeonghyeokdo.github.io/SkateFormer_site/)
- (arXiv 2024.03) Enhancing Video Transformers for Action Understanding with VLM-aided Training, [[Paper]](https://arxiv.org/pdf/2403.16128.pdf)
- (arXiv 2024.04) Action Detection via an Image Diffusion Process, [[Paper]](https://arxiv.org/pdf/2404.01051.pdf)
- (arXiv 2024.04) Dual DETRs for Multi-Label Temporal Action Detection, [[Paper]](https://arxiv.org/pdf/2404.00653.pdf),[[Code]](https://github.com/MCG-NJU/DualDETR)
- (arXiv 2024.04) ASTRA: An Action Spotting TRAnsformer for Soccer Videos, [[Paper]](https://arxiv.org/pdf/2404.01891.pdf)
- (arXiv 2024.04) Design and Analysis of Efficient Attention in Transformers for Social Group Activity Recognition, [[Paper]](https://arxiv.org/pdf/2404.09964.pdf)
- (arXiv 2024.05) A Semantic and Motion-Aware Spatiotemporal Transformer Network for Action Detection,  [[Paper]](https://arxiv.org/pdf/2405.08204.pdf)
- (arXiv 2024.05) From CNNs to Transformers in Multimodal Human Action Recognition: A Survey,  [[Paper]](https://arxiv.org/pdf/2405.15813.pdf)
- (arXiv 2024.06) MALT: Multi-scale Action Learning Transformer for Online Action Detection,  [[Paper]](https://arxiv.org/pdf/2405.20892.pdf)
- (arXiv 2024.06) Feature Fusion for Human Activity Recognition using Parameter-Optimized Multi-Stage Graph Convolutional Network and Transformer Models,  [[Paper]](https://arxiv.org/pdf/2406.16338.pdf)
- (arXiv 2024.07) Multi-State-Action Tokenisation in Decision Transformers for Multi-Discrete Action Spaces,  [[Paper]](https://arxiv.org/pdf/2407.01310.pdf)
- (arXiv 2024.07) Dark Transformer: A Video Transformer for Action Recognition in the Dark,  [[Paper]](https://arxiv.org/pdf/2407.12805.pdf)
- (arXiv 2024.07) Frequency Guidance Matters: Skeletal Action Recognition by Frequency-Aware Mixed Transformer,  [[Paper]](https://arxiv.org/pdf/2407.12322.pdf)
- (arXiv 2024.07) LORTSAR: Low-Rank Transformer for Skeleton-based Action Recognition,  [[Paper]](https://arxiv.org/pdf/2407.14655.pdf)
- (arXiv 2024.08) MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition,  [[Paper]](https://arxiv.org/pdf/2408.00420.pdf)
- (arXiv 2024.08) MultiFuser: Multimodal Fusion Transformer for Enhanced Driver Action Recognition,  [[Paper]](https://arxiv.org/pdf/2408.01766.pdf)
- (arXiv 2024.08) Online Temporal Action Localization with Memory-Augmented Transformer,  [[Paper]](https://arxiv.org/pdf/2408.02957.pdf),[[Code]](https://github.com/skhcjh231/MATR_codebase)
- (arXiv 2024.08) HAT: History-Augmented Anchor Transformer for Online Temporal Action Localization,  [[Paper]](https://arxiv.org/pdf/2408.06437.pdf),[[Code]](https://github.com/sakibreza/ECCV24-HAT/)
- (arXiv 2024.08) Long-Term Pre-training for Temporal Action Detection with Transformers,  [[Paper]](https://arxiv.org/pdf/2408.13152.pdf)
- (arXiv 2024.08) Temporal Divide-and-Conquer Anomaly Actions Localization in Semi-Supervised Videos with Hierarchical Transformer,  [[Paper]](https://arxiv.org/pdf/2408.13643.pdf)
- (arXiv 2024.08) Prediction-Feedback DETR for Temporal Action Detection,  [[Paper]](https://arxiv.org/pdf/2408.16729.pdf)
- (arXiv 2024.08) SITAR: Semi-supervised Image Transformer for Action Recognition,  [[Paper]](https://arxiv.org/pdf/2409.02910.pdf)
- (arXiv 2024.09) ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL,  [[Paper]](https://arxiv.org/pdf/2409.05749.pdf),[[Code]](https://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL)
- (arXiv 2024.09) InterACT: Inter-dependency Aware Action Chunking with Hierarchical Attention Transformers for Bimanual Manipulation,  [[Paper]](https://arxiv.org/pdf/2409.07914.pdf)
- (arXiv 2024.10) Deep Learning for Active Region Classification: A Systematic Study from Convolutional Neural Networks to Vision Transformers,  [[Paper]](https://arxiv.org/pdf/2410.17816.pdf)
- (arXiv 2024.10) LiGAR: LiDAR-Guided Hierarchical Transformer for Multi-Modal Group Activity Recognition,  [[Paper]](https://arxiv.org/pdf/2410.21108.pdf)
- (arXiv 2024.10) Spatio-temporal Transformers for Action Unit Classification with Event Cameras,  [[Paper]](https://arxiv.org/pdf/2410.21958.pdf)
- (arXiv 2024.11) Autoregressive Adaptive Hypergraph Transformer for Skeleton-based Activity Recognition,  [[Paper]](https://arxiv.org/pdf/2411.05692.pdf)
- (arXiv 2025.01) FreqMixFormerV2: Lightweight Frequency-aware Mixed Transformer for Human Skeleton Action Recognition,  [[Paper]](https://arxiv.org/pdf/2412.20621.pdf),[[Code]](https://github.com/wenhanwu95/FreqMixFormer)
- (arXiv 2025.01) Overcoming Semantic Dilution in Transformer-Based Next Frame Prediction,  [[Paper]](https://arxiv.org/pdf/2501.16753.pdf)
- (arXiv 2025.02) SelaFD:Seamless Adaptation of Vision Transformer Fine-tuning for Radar-based Human Activity,  [[Paper]](https://arxiv.org/pdf/2502.04740.pdf),[[Code]](https://github.com/wangyijunlyy/SelaFD)
- (arXiv 2025.02) BST: Badminton Stroke-type Transformer for Skeleton-based Action Recognition in Racket Sports,  [[Paper]](https://arxiv.org/pdf/2502.21085.pdf)
- (arXiv 2025.03) End-to-End Action Segmentation Transformer,  [[Paper]](https://arxiv.org/pdf/2503.06316.pdf)
- (arXiv 2025.03) Context-Enhanced Memory-Refined Transformer for Online Action Detection,  [[Paper]](https://arxiv.org/pdf/2503.18359.pdf),[[Code]](https://github.com/pangzhan27/CMeRT)
- (arXiv 2025.03) MultiTSF: Transformer-based Sensor Fusion for Human-Centric Multi-view and Multi-modal Action Recognition,  [[Paper]](https://arxiv.org/pdf/2504.02279)
- (arXiv 2025.03) MultiSensor-Home: A Wide-area Multi-modal Multi-view Dataset for Action Recognition and Transformer-based Sensor Fusion,  [[Paper]](https://arxiv.org/pdf/2504.02287) 
- (arXiv 2025.04) WiFi based Human Fall and Activity Recognition using Transformer based Encoder Decoder and Graph Neural Networks,  [[Paper]](https://arxiv.org/pdf/2504.16655) 
- (arXiv 2025.05) DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer,  [[Paper]](https://arxiv.org/pdf/2505.05711),[[Code]](https://github.com/Dotori-HJ/DiGIT) 
- (arXiv 2025.06) HRTR: A Single-stage Transformer for Fine-grained Sub-second Action Segmentation in Stroke Rehabilitation,  [[Paper]](https://arxiv.org/pdf/2506.02472)
- (arXiv 2025.06) Pose Matters: Evaluating Vision Transformers and CNNs for Human Action Recognition on Small COCO Subsets,  [[Paper]](https://arxiv.org/pdf/2506.11678)
- (arXiv 2025.08) UniSTFormer: Unified Spatio-Temporal Lightweight Transformer for Efficient Skeleton-Based Action Recognition,  [[Paper]](https://arxiv.org/pdf/2508.08944),[[Code]](https://github.com/wenhanwu95/FreqMixFormer/tree/main/UniSTFormer)
- (arXiv 2025.09) CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition,  [[Paper]](https://arxiv.org/pdf/2509.00692)
- (arXiv 2025.09) MMeViT: Multi-Modal ensemble ViT for Post-Stroke Rehabilitation Action Recognition,  [[Paper]](https://arxiv.org/pdf/2509.23044),[[Code]](https://github.com/ye-Kim/MMeViT)
