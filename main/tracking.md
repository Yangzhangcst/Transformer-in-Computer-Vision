### Tracking
- (EMNLP'19) Effective Use of Transformer Networks for Entity Tracking, [[Paper]](https://arxiv.org/pdf/1909.02635), [[Code]](https://github.com/aditya2211/transformer-entity-tracking)
- (CVPR'21) Transformer Tracking, [[Paper]](https://arxiv.org/pdf/2103.15436), [[Code]](https://github.com/chenxin-dlut/TransT)
- (CVPR'21) Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking, [[Paper]](https://arxiv.org/pdf/2103.11681.pdf), [[Code]](https://github.com/594422814/TransformerTrack)
- (arXiv 2020.12) TransTrack: Multiple-Object Tracking with Transformer, [[Paper]](https://arxiv.org/pdf/2012.15460), [[Code]](https://github.com/PeizeSun/TransTrack)
- (arXiv 2021.01) TrackFormer: Multi-Object Tracking with Transformers, [[Paper]](https://arxiv.org/pdf/2101.02702)
- (arXiv 2021.03) TransCenter: Transformers with Dense Queries for Multiple-Object Tracking, [[Paper]](https://arxiv.org/abs/2103.15145)
- (arXiv 2021.03) Learning Spatio-Temporal Transformer for Visual Tracking, [[Paper]](https://arxiv.org/abs/2103.17154), [[Code]](https://github.com/researchmm/Stark)
- (arXiv 2021.04) Multitarget Tracking with Transformers, [[Paper]](https://arxiv.org/pdf/2104.00734.pdf) 
- (arXiv 2021.04) Spatial-Temporal Graph Transformer for Multiple Object Tracking, [[Paper]](https://arxiv.org/abs/2104.00194)
- (arXiv 2021.05) MOTR: End-to-End Multiple-Object Tracking with TRansformer, [[Paper]](https://arxiv.org/pdf/2105.03247.pdf), [[Code]](https://github.com/megvii-model/MOTR)
- (arXiv 2021.05) TrTr: Visual Tracking with Transformer, [[Paper]](https://arxiv.org/pdf/2105.03817.pdf), [[Code]](https://github.com/tongtybj/TrTr)
- (arXiv 2021.08) HiFT: Hierarchical Feature Transformer for Aerial Tracking, [[Paper]](https://arxiv.org/pdf/2108.00202.pdf), [[Code]](https://github.com/vision4robotics/HiFT)
- (arXiv 2021.10) Siamese Transformer Pyramid Networks for Real-Time UAV Tracking, [[Paper]](https://arxiv.org/pdf/2110.08822.pdf), [[Code]](https://github.com/RISCNYUAD/SiamTPNTracker)
- (arXiv 2021.10) 3D Object Tracking with Transformer, [[Paper]](https://arxiv.org/pdf/2110.14921.pdf), [[Code]](https://github.com/3bobo/lttr)
- (arXiv 2021.12) SwinTrack: A Simple and Strong Baseline for Transformer Tracking, [[Paper]](https://arxiv.org/pdf/2112.00995.pdf), [[Code]](https://github.com/LitingLin/SwinTrack)
- (arXiv 2021.12) PTTR: Relational 3D Point Cloud Object Tracking with Transformer, [[Paper]](https://arxiv.org/pdf/2112.02857.pdf), [[Code]](https://github.com/Jasonkks/PTTR)
- (arXiv 2021.12) Learning Tracking Representations via Dual-Branch Fully Transformer Networks, [[Paper]](https://arxiv.org/pdf/2112.02571.pdf), [[Code]](https://github.com/phiphiphi31/DualTFR)
- (arXiv 2021.12) Efficient Visual Tracking with Exemplar Transformers, [[Paper]](https://arxiv.org/pdf/2112.09686.pdf), [[Code]](https://github.com/visionml/pytracking)
- (arXiv 2022.03) Transforming Model Prediction for Tracking, [[Paper]](https://arxiv.org/pdf/2203.11192.pdf), [[Code]](https://github.com/visionml/pytracking)
- (arXiv 2022.03) MixFormer: End-to-End Tracking with Iterative Mixed Attention, [[Paper]](https://arxiv.org/pdf/2203.11082.pdf), [[Code]](https://github.com/MCG-NJU/MixFormer)
- (arXiv 2022.03) Global Tracking Transformers, [[Paper]](https://arxiv.org/pdf/2203.13250.pdf), [[Code]](https://github.com/xingyizhou/GTR)
- (arXiv 2022.03) Keypoints Tracking via Transformer Networks, [[Paper]](https://arxiv.org/pdf/2203.12848.pdf), [[Code]](https://github.com/LexaNagiBator228/Keypoints-Tracking-via-Transformer-Networks/)
- (arXiv 2022.03) High-Performance Transformer Tracking, [[Paper]](https://arxiv.org/pdf/2203.13533.pdf), [[Code]](https://github.com/chenxin-dlut/TransT-M)
- (arXiv 2022.03) Efficient Visual Tracking via Hierarchical Cross-Attention Transformer, [[Paper]](https://arxiv.org/pdf/2203.13537.pdf), [[Code]](https://github.com/chenxin-dlut/HCAT)
- (arXiv 2022.03) Unified Transformer Tracker for Object Tracking, [[Paper]](https://arxiv.org/pdf/2203.15175.pdf), [[Code]](https://github.com/Flowerfan/Trackron)
- (arXiv 2022.03) Global Tracking via Ensemble of Local Trackers, [[Paper]](https://arxiv.org/pdf/2203.16092.pdf)
- (arXiv 2022.03) MeMOT: Multi-Object Tracking with Memory, [[Paper]](https://arxiv.org/pdf/2203.16761.pdf)
- (arXiv 2022.05) SparseTT: Visual Tracking with Sparse Transformers, [[Paper]](https://arxiv.org/pdf/2205.03776.pdf), [[Code]](https://github.com/fzh0917/SparseTT)
- (arXiv 2022.05) Transformer Tracking with Cyclic Shifting Window Attention, [[Paper]](https://arxiv.org/pdf/2205.03806.pdf), [[Code]](https://github.com/SkyeSong38/CSWinTT)
- (arXiv 2022.05) Transformers for Multi-Object Tracking on Point Clouds, [[Paper]](https://arxiv.org/pdf/2205.15730.pdf)
- (arXiv 2022.05) Joint Spatial-Temporal and Appearance Modeling with Transformer for Multiple Object Tracking, [[Paper]](https://arxiv.org/pdf/2205.15495.pdf), [[Code]](https://github.com/icicle4/TranSTAM)
- (arXiv 2022.07) AiATrack: Attention in Attention for Transformer Visual Tracking, [[Paper]](https://arxiv.org/pdf/2207.09603.pdf), [[Code]](https://github.com/Little-Podi/AiATrack)
- (arXiv 2022.07) 3D Siamese Transformer Network for Single Object Tracking on Point Clouds, [[Paper]](https://arxiv.org/pdf/2207.11995.pdf), [[Code]](https://github.com/fpthink/STNet)
- (arXiv 2022.08) Local Perception-Aware Transformer for Aerial Tracking, [[Paper]](https://arxiv.org/pdf/2208.00662.pdf), [[Code]](https://github.com/vision4robotics/LPAT)
- (arXiv 2022.08) Transformer-based assignment decision network for multiple object tracking, [[Paper]](https://arxiv.org/pdf/2208.03571.pdf), [[Code]](https://github.com/psaltaath/tadn-mot)
- (arXiv 2022.08) InterTrack: Interaction Transformer for 3D Multi-Object Tracking, [[Paper]](https://arxiv.org/pdf/2208.08041.pdf)
- (arXiv 2022.08) Learning Spatial-Frequency Transformer for Visual Object Tracking, [[Paper]](https://arxiv.org/pdf/2208.08829.pdf), [[Code]](https://github.com/Tchuanm/SFTransT.git)
- (arXiv 2022.09) Real-time 3D Single Object Tracking with Transformer, [[Paper]](https://arxiv.org/pdf/2209.00860.pdf), [[Code]](https://github.com/shanjiayao/PTT)
- (arXiv 2022.10) Strong-TransCenter: Improved Multi-Object Tracking based on Transformers with Dense Representations, [[Paper]](https://arxiv.org/pdf/2210.13570.pdf), [[Code]](https://github.com/amitgalor18/STC_Tracker)
- (arXiv 2022.10) End-to-end Tracking with a Multi-query Transformer, [[Paper]](https://arxiv.org/pdf/2210.14601.pdf)
- (arXiv 2022.10) Can Transformer Attention Spread Give Insights Into Uncertainty of Detected and Tracked Objects, [[Paper]](https://arxiv.org/pdf/2210.14391.pdf)
- (arXiv 2022.10) ProContEXT: Exploring Progressive Context Transformer for Tracking, [[Paper]](https://arxiv.org/pdf/2210.15511.pdf), [[Code]](https://shorturl.at/jnNT2)
- (arXiv 2022.11) GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds, [[Paper]](https://arxiv.org/pdf/2211.10927.pdf), [[Code]](https://github.com/haooozi/GLT-T)
- (arXiv 2023.01) Multi-target multi-camera vehicle tracking using transformer-based camera link model and spatial-temporal information, [[Paper]](https://arxiv.org/pdf/2301.07805.pdf)
- (arXiv 2023.01) Compact Transformer Tracker with Correlative Masked Modeling, [[Paper]](https://arxiv.org/pdf/2301.10938.pdf), [[Project]](https://github.com/HUSTDML/CTTrack)
- (arXiv 2023.01) MixFormer: End-to-End Tracking withIterative Mixed Attention, [[Paper]](https://arxiv.org/pdf/2302.02814.pdf), [[Code]](https://github.com/MCG-NJU/MixFormer)
- (arXiv 2023.02) Transformers in Single Object Tracking: An Experimental Survey, [[Paper]](https://arxiv.org/pdf/2302.11867.pdf)
- (arXiv 2023.03) SGDViT: Saliency-Guided Dynamic Vision Transformer for UAV Tracking, [[Paper]](https://arxiv.org/pdf/2303.04378.pdf), [[Code]](https://github.com/vision4robotics/SGDViT)
- (arXiv 2023.03) Event-based Human Pose Tracking by Spiking Spatiotemporal Transformer, [[Paper]](https://arxiv.org/pdf/2303.09681.pdf), [[Code]](https://github.com/JimmyZou/HumanPoseTracking_SNN)
- (arXiv 2023.03) Tracker Meets Night: A Transformer Enhancer for UAV Tracking, [[Paper]](https://arxiv.org/pdf/2303.10951.pdf), [[Code]](https://github.com/vision4robotics/SCT)
- (arXiv 2023.03) RGBT Tracking via Progressive Fusion Transformer with Dynamically Guided Learning, [[Paper]](https://arxiv.org/pdf/2303.14778.pdf)
- (arXiv 2023.03) Generalized Relation Modeling for Transformer Tracking, [[Paper]](https://arxiv.org/pdf/2303.16580.pdf), [[Code]](https://github.com/Little-Podi/GRM)
- (arXiv 2023.04) GLT-T++: Global-Local Transformer for 3D Siamese Tracking with Ranking Loss, [[Paper]](https://arxiv.org/pdf/2304.00242.pdf), [[Code]](https://github.com/haooozi/GLT-T)
- (arXiv 2023.05) MixFormerV2: Efficient Fully Transformer Tracking, [[Paper]](https://arxiv.org/pdf/2305.15896.pdf), [[Code]](https://github.com/MCG-NJU/MixFormerV2)
- (arXiv 2023.05) Humans in 4D: Reconstructing and Tracking Humans with Transformers, [[Paper]](https://arxiv.org/pdf/2305.20091.pdf), [[Code]](https://shubham-goel.github.io/4dhumans/)
- (arXiv 2023.06) TrajectoryFormer: 3D Object Tracking Transformer with Predictive Trajectory Hypotheses, [[Paper]](https://arxiv.org/pdf/2306.05888.pdf)
- (arXiv 2023.06) MotionTrack: End-to-End Transformer-based Multi-Object Tracing with LiDAR-Camera Fusion, [[Paper]](https://arxiv.org/pdf/2306.17000.pdf)
- (arXiv 2023.07) Cross-modal Orthogonal High-rank Augmentation for RGB-Event Transformer-trackers, [[Paper]](https://arxiv.org/pdf/2307.04129.pdf)
- (arXiv 2023.07) CoTracker: It is Better to Track Together, [[Paper]](https://arxiv.org/pdf/2307.07635.pdf), [[Code]](https://co-tracker.github.io/)
- (arXiv 2023.07) ConTrack: Contextual Transformer for Device Tracking in X-ray, [[Paper]](https://arxiv.org/pdf/2307.07541.pdf)
- (arXiv 2023.07) MeMOTR: Long-Term Memory-Augmented Transformer for Multi-Object Tracking, [[Paper]](https://arxiv.org/pdf/2307.15700.pdf)
- (arXiv 2023.08) Robust Object Modeling for Visual Tracking, [[Paper]](https://arxiv.org/pdf/2308.05140.pdf), [[Code]](https://github.com/dawnyc/ROMTrack)
- (arXiv 2023.08) Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking, [[Paper]](https://arxiv.org/pdf/2308.06904.pdf), [[Code]](https://github.com/kangben258/HiT)
- (arXiv 2023.08) 3DMOTFormer: Graph Transformer for Online 3D Multi-Object Tracking, [[Paper]](https://arxiv.org/pdf/2308.06635.pdf), [[Code]](https://github.com/dsx0511/3DMOTFormer)
- (arXiv 2023.08) BOTT: Box Only Transformer Tracker for 3D Object Tracking, [[Paper]](https://arxiv.org/pdf/2308.08753.pdf)
- (arXiv 2023.08) Delving into Motion-Aware Matching for Monocular 3D Object Tracking, [[Paper]](https://arxiv.org/pdf/2308.11607.pdf), [[Code]](https://github.com/kuanchihhuang/MoMA-M3T)
- (arXiv 2023.08) CiteTracker: Correlating Image and Text for Visual Tracking, [[Paper]](https://arxiv.org/pdf/2308.11322.pdf), [[Code]](https://github.com/NorahGreen/CiteTracker)
- (arXiv 2023.08) Fixating on Attention: Integrating Human Eye Tracking into Vision Transformers, [[Paper]](https://arxiv.org/pdf/2308.13969.pdf), [[Code]](https://github.com/schko/fixatt)
- (arXiv 2023.08) Unified Single-Stage Transformer Network for Efficient RGB-T Tracking, [[Paper]](https://arxiv.org/pdf/2308.13764.pdf)
- (arXiv 2023.08) Group Regression for Query Based Object Detection and Tracking, [[Paper]](https://arxiv.org/pdf/2308.14481.pdf)
- (arXiv 2023.08) RGB-T Tracking via Multi-Modal Mutual Prompt Learning, [[Paper]](https://arxiv.org/ftp/arxiv/papers/2308/2308.16386.pdf), [[Code]](https://github.com/HusterYoung/MPLT)
- (arXiv 2023.09) Efficient Training for Visual Tracking with Deformable Transformer, [[Paper]](https://arxiv.org/pdf/2309.02676.pdf), [[Code]](https://github.com/HusterYoung/MPLT)
- (arXiv 2023.09) Separable Self and Mixed Attention Transformers for Efficient Object Tracking, [[Paper]](https://arxiv.org/pdf/2309.03979.pdf), [[Code]](https://github.com/goutamyg/SMAT)
- (arXiv 2023.09) Transparent Object Tracking with Enhanced Fusion Module, [[Paper]](https://arxiv.org/pdf/2309.06701.pdf), [[Code]](https://github.com/kalyan0510/TOTEM)
- (arXiv 2023.09) Leveraging the Power of Data Augmentation for Transformer-based Tracking, [[Paper]](https://arxiv.org/pdf/2309.08264.pdf)
- (arXiv 2023.09) LiteTrack: Layer Pruning with Asynchronous Feature Extraction for Lightweight and Efficient Visual Tracking, [[Paper]](https://arxiv.org/pdf/2309.09249.pdf), [[Code]](https://github.com/TsingWei/LiteTrack)
- (arXiv 2023.10) Lightweight Full-Convolutional Siamese Tracker, [[Paper]](https://arxiv.org/pdf/2310.05392.pdf), [[Code]](https://github.com/LiYunfengLYF/LightFC)
- (arXiv 2023.10) MO-YOLO: End-to-End Multiple-Object Tracking Method with YOLO and MOTR, [[Paper]](https://arxiv.org/pdf/2310.17170.pdf)
- (arXiv 2023.10) Siamese-DETR for Generic Multi-Object Tracking, [[Paper]](https://arxiv.org/pdf/2310.17875.pdf)
- (arXiv 2023.11) LabelFormer: Object Trajectory Refinement for Offboard Perception from LiDAR Point Clouds, [[Paper]](https://arxiv.org/pdf/2311.01444.pdf)
- (arXiv 2023.11) Contrastive Learning for Multi-Object Tracking with Transformers, [[Paper]](https://arxiv.org/pdf/2311.08043.pdf)
- (arXiv 2023.11) Single-Model and Any-Modality for Video Object Tracking, [[Paper]](https://arxiv.org/pdf/2311.15851.pdf), [[Code]](https://github.com/Zongwei97/UnTrack)
- (arXiv 2023.12) Multi-Correlation Siamese Transformer Network with Dense Connection for 3D Single Object Tracking, [[Paper]](https://arxiv.org/pdf/2312.11051.pdf), [[Code]](https://github.com/liangp/MCSTN-3DSOT)
- (arXiv 2023.12) Transformer Network for Multi-Person Tracking and Re-Identification in Unconstrained Environment, [[Paper]](https://arxiv.org/pdf/2312.11929.pdf)
- (arXiv 2024.01) Transformer RGBT Tracking with Spatio-Temporal Multimodal Tokens, [[Paper]](https://arxiv.org/pdf/2401.01674.pdf)
- (arXiv 2024.01) Correlation-Embedded Transformer Tracking: A Single-Branch Framework, [[Paper]](https://arxiv.org/pdf/2401.12743.pdf), [[Code]](https://github.com/phiphiphi31/SBT)
- (arXiv 2024.02) Optimized Information Flow for Transformer Tracking, [[Paper]](https://arxiv.org/pdf/2402.08195.pdf), [[Code]](https://github.com/JananiKugaa/OIFTrack)
- (arXiv 2024.02) OLViT: Multi-Modal State Tracking via Attention-Based Embeddings for Video-Grounded Dialog, [[Paper]](https://arxiv.org/pdf/2402.13146.pdf)
- (arXiv 2024.03) Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance, [[Paper]](https://arxiv.org/pdf/2403.05231.pdf)
- (arXiv 2024.03) Autoregressive Queries for Adaptive Tracking with Spatio-TemporalTransformers, [[Paper]](https://arxiv.org/pdf/2403.10574.pdf), [[Code]](https://github.com/orgs/GXNU-ZhongLab)
- (arXiv 2024.03) TAPTR: Tracking Any Point with Transformers as Detection, [[Paper]](https://arxiv.org/pdf/2403.13042.pdf), [[Code]](https://github.com/IDEA-Research/TAPTR)
- (arXiv 2024.03) ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras Based on Transformer, [[Paper]](https://arxiv.org/pdf/2403.14626.pdf)
- (arXiv 2024.03) Exploring Dynamic Transformer for Efficient Object Tracking, [[Paper]](https://arxiv.org/pdf/2403.17651.pdf)
- (arXiv 2024.04) PillarTrack: Redesigning Pillar-based Transformer Network for Single Object Tracking on Point Clouds, [[Paper]](https://arxiv.org/pdf/2404.07495.pdf), [[Code]](https://github.com/StiphyJay/PillarTrack)
- (arXiv 2024.04) STT: Stateful Tracking with Transformers for Autonomous Driving, [[Paper]](https://arxiv.org/pdf/2405.00236.pdf)
- (arXiv 2024.05) Transformer-based RGB-T Tracking with Channel and Spatial Feature Fusion, [[Paper]](https://arxiv.org/pdf/2405.03177.pdf), [[Code]](https://github.com/LiYunfengLYF/CSTNet)
- (arXiv 2024.05) PuTR: A Pure Transformer for Decoupled and Online Multi-Object Tracking, [[Paper]](https://arxiv.org/pdf/2405.14119.pdf), [[Code]](https://github.com/chongweiliu/PuTR)
- (arXiv 2024.05) LoReTrack: Efficient and Accurate Low-Resolution Transformer Tracking, [[Paper]](https://arxiv.org/pdf/2405.17660.pdf), [[Code]](https://github.com/ShaohuaDong2021/LoReTrack)
- (arXiv 2024.05) Reliable Object Tracking by Multimodal Hybrid Feature Extraction and Transformer-Based Fusion, [[Paper]](https://arxiv.org/pdf/2405.17903.pdf)
- (arXiv 2024.06) Adaptively Bypassing Vision Transformer Blocks for Efficient Visual Tracking, [[Paper]](https://arxiv.org/pdf/2406.08037.pdf), [[Code]](https://github.com/1HykhqV3rU/ABTrack)
- (arXiv 2024.07) eMoE-Tracker: Environmental MoE-based Transformer for Robust Event-guided Object Tracking, [[Paper]](https://arxiv.org/pdf/2406.20024.pdf), [[Code]](https://vlislab22.github.io/eMoE-Tracker/)
- (arXiv 2024.07) EUDA: An Efficient Unsupervised Domain Adaptation via Self-Supervised Vision Transformer, [[Paper]](https://arxiv.org/pdf/2407.21311.pdf), [[Code]](https://github.com/A-Abedi/EUDA)
- (arXiv 2024.08) Cross-modulated Attention Transformer for RGBT Tracking, [[Paper]](https://arxiv.org/pdf/2408.02222.pdf)
- (arXiv 2024.08) MCTR: Multi Camera Tracking Transformer, [[Paper]](https://arxiv.org/pdf/2408.13243.pdf)
- (arXiv 2024.09) General Compression Framework for Efficient Transformer Object Tracking, [[Paper]](https://arxiv.org/pdf/2409.17564.pdf), [[Code]](https://github.com/LingyiHongfd/CompressTracker)
- (arXiv 2024.10) Temporal-Enhanced Multimodal Transformer for Referring Multi-Object Tracking and Segmentation, [[Paper]](https://arxiv.org/pdf/2410.13437.pdf)
- (arXiv 2025.01) Track-On: Transformer-based Online Point Tracking with Memory, [[Paper]](https://arxiv.org/pdf/2501.18487.pdf), [[Code]](https://kuis-ai.github.io/track_on)
- (arXiv 2025.02) Enhanced Transformer-Based Tracking for Skiing Events: Overcoming Multi-Camera Challenges, Scale Variations and Rapid Motion -- SkiTB Visual Tracking Challenge 2025, [[Paper]](https://arxiv.org/pdf/2502.18867.pdf)
- (arXiv 2025.02) Spectral-Enhanced Transformers: Leveraging Large-Scale Pretrained Models for Hyperspectral Object Tracking, [[Paper]](https://arxiv.org/pdf/2502.18748.pdf)
- (arXiv 2025.03) Target-aware Bidirectional Fusion Transformer for Aerial Object Tracking, [[Paper]](https://arxiv.org/pdf/2503.09951.pdf)
- (arXiv 2025.03) OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer, [[Paper]](https://arxiv.org/pdf/2503.10616.pdf), [[Code]](https://github.com/jinyanglii/OVTR)
- (arXiv 2025.03) COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking, [[Paper]](https://arxiv.org/pdf/2504.01321.pdf)
- (arXiv 2025.05) Modality-Guided Dynamic Graph Fusion and Temporal Diffusion for Self-Supervised RGB-T Tracking, [[Paper]](https://arxiv.org/pdf/2505.03507.pdf), [[Code]](https://github.com/LiShenglana/GDSTrack)
- (arXiv 2025.06) Lightweight RGB-T Tracking with Mobile Vision Transformers, [[Paper]](https://arxiv.org/pdf/2506.19154.pdf)
- (arXiv 2025.08) Vision transformer-based multi-camera multi-object tracking framework for dairy cow monitoring, [[Paper]](https://arxiv.org/pdf/2508.01752.pdf)
- (arXiv 2025.08) SMTrack: End-to-End Trained Spiking Neural Networks for Multi-Object Tracking in RGB Videos, [[Paper]](https://arxiv.org/pdf/2508.14607.pdf)
- (arXiv 2025.09) Motion-Aware Transformer for Multi-Object Tracking, [[Paper]](https://arxiv.org/pdf/2509.21715.pdf)
- (arXiv 2025.10) FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking, [[Paper]](https://arxiv.org/pdf/2510.19981.pdf)
