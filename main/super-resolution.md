### Super-Resolution
- (CVPR'20) Learning Texture Transformer Network for Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2006.04139), [[Code]](https://github.com/researchmm/TTSR)
- (arXiv 2021.06) LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution Homography Estimation, [[Paper]](https://arxiv.org/pdf/2006.04139)
- (arXiv 2021.06) Video Super-Resolution Transformer, [[Paper]](https://arxiv.org/pdf/2106.06847.pdf), [[Code]](https://github.com/caojiezhang/VSR-Transformer)
- (arXiv 2021.08) Light Field Image Super-Resolution with Transformers, [[Paper]](https://arxiv.org/pdf/2108.07597.pdf), [[Code]](https://github.com/ZhengyuLiang24/LFT)
- (arXiv 2021.08) Efficient Transformer for Single Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2108.11084.pdf)
- (arXiv 2021.09) Fusformer: A Transformer-based Fusion Approach for Hyperspectral Image Super-resolution, [[Paper]](https://arxiv.org/pdf/2109.02079.pdf)
- (arXiv 2021.12) Implicit Transformer Network for Screen Content Image Continuous Super-Resolution, [[Paper]](https://arxiv.org/pdf/2112.06174.pdf)
- (arXiv 2021.12) On Efficient Transformer and Image Pre-training for Low-level Vision, [[Paper]](https://arxiv.org/pdf/2112.10175.pdf), [[Code]](https://github.com/fenglinglwb/EDT)
- (arXiv 2022.01) Detail-Preserving Transformer for Light Field Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2201.00346.pdf), [[Code]](https://github.com/BITszwang/DPT)
- (arXiv 2022.03) Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution, [[Paper]](https://arxiv.org/pdf/2203.07682.pdf)
- (arXiv 2022.03) HIPA: Hierarchical Patch Transformer for Single Image Super Resolution, [[Paper]](https://arxiv.org/pdf/2203.10247.pdf)
- (arXiv 2022.03) RSTT: Real-time Spatial Temporal Transformer for Space-Time Video Super-Resolution, [[Paper]](https://arxiv.org/pdf/2203.14186.pdf), [[Code]](https://github.com/llmpass/RSTT)
- (arXiv 2022.04) Learning Trajectory-Aware Transformer for Video Super-Resolution, [[Paper]](https://arxiv.org/pdf/2204.04216.pdf), [[Code]](https://github.com/researchmm/TTVSR)
- (arXiv 2022.04) BSRT: Improving Burst Super-Resolution with Swin Transformer and Flow-Guided Deformable Alignment, [[Paper]](https://arxiv.org/pdf/2204.08332.pdf), [[Code]](https://github.com/Algolzw/BSRT)
- (arXiv 2022.04) Self-Calibrated Efficient Transformer for Lightweight Super-Resolution, [[Paper]](https://arxiv.org/pdf/2204.08913.pdf), [[Code]](https://github.com/AlexZou14/SCET)
- (arXiv 2022.04) CTCNet: A CNN-Transformer Cooperation Network for Face Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2204.08696.pdf)
- (arXiv 2022.04) A New Dataset and Transformer for Stereoscopic Video Super-Resolution, [[Paper]](https://arxiv.org/pdf/2204.10039.pdf), [[Code]](https://github.com/H-deep/Trans-SVSR/)
- (arXiv 2022.04) Lightweight Bimodal Network for Single-Image Super-Resolution via Symmetric CNN and Recursive Transformer, [[Paper]](https://arxiv.org/pdf/2204.13286.pdf), [[Code]](https://github.com/IVIPLab/LBNet)
- (arXiv 2022.05) Activating More Pixels in Image Super-Resolution Transformer, [[Paper]](https://arxiv.org/pdf/2205.04437.pdf), [[Code]](https://github.com/chxy95/HAT)
- (arXiv 2022.06) Bilateral Network with Channel Splitting Network and Transformer for Thermal Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2206.12046.pdf)
- (arXiv 2022.07) Rethinking Alignment in Video Super-Resolution Transformers,  [[Paper]](https://arxiv.org/pdf/2207.08494.pdf), [[Code]](https://github.com/XPixelGroup/RethinkVSRAlignment)
- (arXiv 2022.07) Reference-based Image Super-Resolution with Deformable Attention Transformer,  [[Paper]](https://arxiv.org/pdf/2207.11938.pdf), [[Code]](https://github.com/caojiezhang/DATSR)
- (arXiv 2022.08) Learning Spatiotemporal Frequency-Transformer for Compressed Video Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2208.03012.pdf), [[Code]](https://github.com/researchmm/FTVSR)
- (arXiv 2022.08) HST: Hierarchical Swin Transformer for Compressed Image Super-resolution,  [[Paper]](https://arxiv.org/pdf/2208.09885.pdf)
- (arXiv 2022.09) Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration,  [[Paper]](https://arxiv.org/pdf/2209.11345.pdf)
- (arXiv 2022.10) Scene Text Image Super-Resolution via Content Perceptual Loss and Criss-Cross Transformer Blocks,  [[Paper]](https://arxiv.org/pdf/2210.06924.pdf)
- (arXiv 2022.10) Learning Texture Transformer Network for Light Field Super-Resolution,  [[Paper]](https://arxiv.org/ftp/arxiv/papers/2210/2210.09293.pdf)
- (arXiv 2022.10) ITSRN++: Stronger and Better Implicit Transformer Network for Continuous Screen Content Image Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2210.08812.pdf)
- (arXiv 2022.10) Single Image Super-Resolution Using Lightweight Networks Based on Swin Transformer,  [[Paper]](https://arxiv.org/pdf/2210.11019.pdf)
- (arXiv 2022.11) N-Gram in Swin Transformers for Efficient Lightweight Image Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2211.11436.pdf)
- (arXiv 2022.12) Learning Spatiotemporal Frequency-Transformer for Low-Quality Video Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2212.14046.pdf), [[Code]](https://github.com/researchmm/FTVSR)
- (arXiv 2023.01) Image Super-Resolution using Efficient Striped Window Transformer,  [[Paper]](https://arxiv.org/pdf/2301.09869.pdf), [[Code]](https://github.com/Fried-Rice-Lab/FriedRiceLab)
- (arXiv 2023.02) OSRT: Omnidirectional Image Super-Resolution with Distortion-aware Transformer,  [[Paper]](https://arxiv.org/pdf/2302.03453.pdf), [[Code]](https://github.com/Fanghua-Yu/OSRT)
- (arXiv 2023.03) CoT-MISR:Marrying Convolution and Transformer for Multi-Image Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2303.06548.pdf)
- (arXiv 2023.03) Recursive Generalization Transformer for Image Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2303.06373.pdf)
- (arXiv 2023.03) SRFormer: Permuted Self-Attention for Single Image Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2303.06373.pdf), [[Code]](https://github.com/HVision-NKU/SRFormer)
- (arXiv 2023.03) LSwinSR: UAV Imagery Super-Resolution based on Linear Swin Transformer,  [[Paper]](https://arxiv.org/pdf/2303.10232.pdf), [[Code]](https://github.com/lironui/LSwinSR)
- (arXiv 2023.03) PFT-SSR: Parallax Fusion Transformer for Stereo Image Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2303.13807.pdf), [[Code]](https://github.com/MIVRC/PFT-PyTorch)
- (arXiv 2023.03) Incorporating Transformer Designs into Convolutions for Lightweight Image Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2303.14324.pdf), [[Code]](https://github.com/Aitical/TCSR)
- (arXiv 2023.03) Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution,  [[Paper]](https://arxiv.org/pdf/2303.16513.pdf), [[Code]](https://github.com/jaroslaw1007/CLIT)
- (arXiv 2023.03) SOSR: Source-Free Image Super-Resolution with Wavelet Augmentation Transformer,  [[Paper]](https://arxiv.org/pdf/2303.17783.pdf)
- (arXiv 2023.05) Local-Global Transformer Enhanced Unfolding Network for Pan-sharpening, [[Paper]](https://arxiv.org/pdf/2304.14612.pdf)
- (arXiv 2023.05) A Vision Transformer Approach for Efficient Near-Field Irregular SAR Super-Resolution, [[Paper]](https://arxiv.org/pdf/2305.02074.pdf)
- (arXiv 2023.05) Hybrid Transformer and CNN Attention Network for Stereo Image Super-resolution, [[Paper]](https://arxiv.org/pdf/2305.05177.pdf)
- (arXiv 2023.05) Efficient Mixed Transformer for Single Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2305.11403.pdf), [[Code]](https://github.com/Fried-Rice-Lab/EMTT)
- (arXiv 2023.05) FIT: Far-reaching Interleaved Transformers, [[Paper]](https://arxiv.org/pdf/2305.12689.pdf), [[Code]](https://github.com/google-research/pix2seq)
- (arXiv 2023.07) MaxSR: Image Super-Resolution Using Improved MaxViT, [[Paper]](https://arxiv.org/pdf/2307.07240.pdf)
- (arXiv 2023.07) DARTS: Double Attention Reference-based Transformer for Super-resolution, [[Paper]](https://arxiv.org/pdf/2307.08837.pdf)
- (arXiv 2023.07) ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution, [[Paper]](https://arxiv.org/pdf/2307.14010.pdf), [[Code]](https://github.com/Rexzhan/ESSAformer/tree/main)
- (arXiv 2023.08) Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2308.05022.pdf), [[Code]](https://github.com/AVC2-UESTC/CRAFT-SR.git)
- (arXiv 2023.08) Dual Aggregation Transformer for Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2308.03364.pdf), [[Code]](https://github.com/zhengchen1999/DAT)
- (arXiv 2023.08) Unfolding Once is Enough: A Deployment-Friendly Transformer Unit for Super-Resolution, [[Paper]](https://arxiv.org/pdf/2308.02794.pdf), [[Code]](https://github.com/yongliuy/DITN)
- (arXiv 2023.08) S2R: Exploring a Double-Win Transformer-Based Framework for Ideal and Blind Super-Resolution, [[Paper]](https://arxiv.org/pdf/2308.08142.pdf), [[Code]](https://github.com/berumotto-vermouth/S2R.12)
- (arXiv 2023.10) Degradation-Aware Self-Attention Based Transformer for Blind Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2310.04180.pdf), [[Code]](https://github.com/I2-Multimedia-Lab/DSAT/tree/main)
- (arXiv 2023.12) SRTransGAN: Image Super-Resolution using Transformer based Generative Adversarial Network, [[Paper]](https://arxiv.org/pdf/2312.01999.pdf)
- (arXiv 2023.12) Transformer-based Selective Super-Resolution for Efficient Image Refinement, [[Paper]](https://arxiv.org/pdf/2312.05803.pdf), [[Code]](https://github.com/destiny301/SSR)
- (arXiv 2023.12) Learn From Orientation Prior for Radiograph Super-Resolution: Orientation Operator Transformer, [[Paper]](https://arxiv.org/pdf/2312.16455.pdf)
- (arXiv 2024.01) Image Super-resolution Reconstruction Network based on Enhanced Swin Transformer via Alternating Aggregation of Local-Global Features, [[Paper]](https://arxiv.org/pdf/2401.00241.pdf)
- (arXiv 2024.01) Beyond Subspace Isolation: Many-to-Many Transformer for Light Field Image Super-resolution, [[Paper]](https://arxiv.org/pdf/2401.00740.pdf)
- (arXiv 2024.01) Transforming Image Super-Resolution: A ConvFormer-based Efficient Approach, [[Paper]](https://arxiv.org/pdf/2401.05633.pdf),[[Code]](https://github.com/Aitical/CFSR)
- (arXiv 2024.01) Video Super-Resolution Transformer with Masked Inter&Intra-Frame Attention, [[Paper]](https://arxiv.org/pdf/2401.06312.pdf),[[Code]](https://github.com/LabShuHangGU/MIA-VSR)
- (arXiv 2024.01) Transcending the Limit of Local Window: Advanced Super-Resolution Transformer with Adaptive Token Dictionary, [[Paper]](https://arxiv.org/pdf/2401.08209.pdf),[[Code]](https://github.com/LabShuHangGU/Adaptive-Token-Dictionary)
- (arXiv 2024.01) LKFormer: Large Kernel Transformer for Infrared Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2401.11589.pdf),[[Code]](https://github.com/sad192/large-kernel-Transformer)
- (arXiv 2024.04) Training Transformer Models by Wavelet Losses Improves Quantitative and Visual Performance in Single Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2404.11273.pdf)
- (arXiv 2024.05) CDFormer:When Degradation Prediction Embraces Diffusion Model for Blind Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2405.07648.pdf),[[Code]](https://github.com/I2-Multimedia-Lab/CDFormer)
- (arXiv 2024.05) Hierarchical Neural Operator Transformer with Learnable Frequency-aware Loss Prior for Arbitrary-scale Super-resolution, [[Paper]](https://arxiv.org/pdf/2405.12202.pdf)
- (arXiv 2024.06) Geometric Distortion Guided Transformer for Omnidirectional Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2406.10869.pdf)
- (arXiv 2024.06) IG-CFAT: An Improved GAN-Based Framework for Effectively Exploiting Transformers in Real-World Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2406.13815.pdf)
- (arXiv 2024.07) HiT-SR: Hierarchical Transformer for Efficient Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2407.05878.pdf)
- (arXiv 2024.07) RealViformer: Investigating Attention for Real-World Video Super-Resolution, [[Paper]](https://arxiv.org/pdf/2407.13987.pdf),[[Code]](https://github.com/Yuehan717/RealViformer)
- (arXiv 2024.07) Efficient Multi-disparity Transformer for Light Field Image Super-resolution, [[Paper]](https://arxiv.org/pdf/2407.15329.pdf)
- (arXiv 2024.08) GRFormer: Grouped Residual Self-Attention for Lightweight Single Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2408.07484.pdf),[[Code]](https://github.com/sisrformer/GRFormer)
- (arXiv 2024.08) ML-CrAIST: Multi-scale Low-high Frequency Information-based Cross black Attention with Image Super-resolving Transformer, [[Paper]](https://arxiv.org/pdf/2408.09940.pdf),[[Code]](https://github.com/Alik033/ML-CrAIST)
- (arXiv 2024.09) HiTSR: A Hierarchical Transformer for Reference-based Super-Resolution, [[Paper]](https://arxiv.org/pdf/2408.16959.pdf),[[Code]](https://github.com/bia006/HiTSR/tree/main?tab=readme-ov-file)
- (arXiv 2024.09) LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2409.03516.pdf),[[Code]](https://github.com/jwgdmkj/LMLT)
- (arXiv 2024.09) Lightweight Multiscale Feature Fusion Super-Resolution Network Based on Two-branch Convolution and Transformer, [[Paper]](https://arxiv.org/pdf/2409.06590.pdf)
- (arXiv 2024.11) Local Implicit Wavelet Transformer for Arbitrary-Scale Super-Resolution, [[Paper]](https://arxiv.org/pdf/2411.06442.pdf),[[Code]](https://github.com/dmhdmhdmh/LIWT)
- (arXiv 2024.11) A Low-Resolution Image is Worth 1x1 Words: Enabling Fine Image Super-Resolution with Transformers and TaylorShift, [[Paper]](https://arxiv.org/pdf/2411.10231.pdf)
- (arXiv 2024.11) HAAT: Hybrid Attention Aggregation Transformer for Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2411.18003.pdf)
- (arXiv 2024.11) MAT: Multi-Range Attention Transformer for Efficient Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2411.17214.pdf)
- (arXiv 2024.11) ΩSFormer: Dual-Modal Ω-like Super-Resolution Transformer Network for Cross-scale and High-accuracy Terraced Field Vectorization Extraction, [[Paper]](https://arxiv.org/pdf/2411.17088.pdf),[[Code]](https://github.com/choubaoy/DMRVD/tree/master)
- (arXiv 2024.12) CubeFormer: A Simple yet Effective Baseline for Lightweight Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2412.02234.pdf)
- (arXiv 2025.01) State-of-the-Art Transformer Models for Image Super-Resolution: Techniques, Challenges, and Applications, [[Paper]](https://arxiv.org/pdf/2501.07855.pdf)
- (arXiv 2025.01) Efficient Attention-Sharing Information Distillation Transformer for Lightweight Single Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2501.15774.pdf),[[Code]](https://github.com/saturnian77/ASID)
- (arXiv 2025.03) QUIET-SR: Quantum Image Enhancement Transformer for Single Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2503.08759.pdf)
- (arXiv 2025.03) Progressive Focused Transformer for Single Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2503.20337.pdf),[[Code]](https://github.com/LabShuHangGU/PFT-SR)
- (arXiv 2025.03) DiT4SR: Taming Diffusion Transformer for Real-World Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2503.23580.pdf)
- (arXiv 2025.03) A Lightweight Image Super-Resolution Transformer Trained on Low-Resolution Images Only, [[Paper]](https://arxiv.org/pdf/2503.23265.pdf),[[Code]](https://github.com/ifnspaml/SuperResolutionMultiscaleTraining)
- (arXiv 2025.05) EAM: Enhancing Anything with Diffusion Transformers for Blind Super-Resolution, [[Paper]](https://arxiv.org/pdf/2505.05209.pdf)
- (arXiv 2025.06) SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution, [[Paper]](https://arxiv.org/pdf/2506.03740.pdf)
- (arXiv 2025.06) DualX-VSR: Dual Axial SpatialTemporal Transformer for Real-World Video Super-Resolution without Motion Compensation, [[Paper]](https://arxiv.org/pdf/2506.04830.pdf)
- (arXiv 2025.09) Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution, [[Paper]](https://arxiv.org/pdf/2509.04824.pdf)
