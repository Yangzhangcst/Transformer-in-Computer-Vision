### Transfer learning
- (arXiv 2021.06) Transformer-Based Source-Free Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2105.14138.pdf), [[Code]](https://github.com/ygjwd12345/TransDA)
- (arXiv 2021.08) TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2108.05988.pdf)
- (arXiv 2021.09) CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2109.06165.pdf)
- (arXiv 2021.10) Investigating Transfer Learning Capabilities of Vision Transformers and CNNs by Fine-Tuning a Single Trainable Block, [[Paper]](https://arxiv.org/pdf/2110.05270.pdf)
- (arXiv 2021.10) Dispensed Transformer Network for Unsupervised Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2110.14944.pdf)
- (arXiv 2021.11) Exploiting Both Domain-specific and Invariant Knowledge via a Win-win Transformer for Unsupervised Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2111.12941.pdf)
- (arXiv 2021.12) Pre-Training Transformers for Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2112.09965.pdf)
- (arXiv 2022.01) Domain Adaptation via Bidirectional Cross-Attention Transformer, [[Paper]](https://arxiv.org/pdf/2201.05887.pdf)
- (arXiv 2022.03) Towards Unsupervised Domain Adaptation via Domain-Transformer, [[Paper]](https://arxiv.org/pdf/2202.13777.pdf)
- (arXiv 2022.03) DATR: Domain-adaptive transformer for multi-domain landmark detection, [[Paper]](https://arxiv.org/pdf/2203.06433.pdf)
- (arXiv 2022.03) simCrossTrans: A Simple Cross-Modality Transfer Learning for Object Detection with ConvNets or Vision Transformers, [[Paper]](https://arxiv.org/pdf/2203.10456.pdf), [[Code]](https://github.com/liketheflower/simCrossTrans)
- (arXiv 2022.04) Safe Self-Refinement for Transformer-based Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2204.07683.pdf), [[Code]](https://github.com/tsun/SSRT)
- (arXiv 2022.05) Improving Transferability for Domain Adaptive Detection Transformers, [[Paper]](https://arxiv.org/pdf/2204.14195.pdf), [[Code]](https://github.com/tsun/SSRT)
- (arXiv 2022.05) Cross-Domain Object Detection with Mean-Teacher Transformer, [[Paper]](https://arxiv.org/pdf/2205.01643.pdf)
- (arXiv 2022.06) Cross-domain Detection Transformer based on Spatial-aware and Semantic-aware Token Alignment, [[Paper]](https://arxiv.org/pdf/2206.00222.pdf)
- (arXiv 2022.08) Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2208.01195.pdf), [[Code]](https://github.com/BIT-DA/Domain-Oriented-Transformer)
- (arXiv 2022.08) How Well Do Vision Transformers (VTs) Transfer To The Non-Natural Image Domain? An Empirical Study Involving Art Classification, [[Paper]](https://arxiv.org/pdf/2208.04693.pdf)
- (arXiv 2022.08) Prompt Vision Transformer for Domain Generalization, [[Paper]](https://arxiv.org/pdf/2208.08914.pdf)
- (arXiv 2022.08) Transfer Learning and Vision Transformer based State-of-Health prediction of Lithium-Ion Batteries, [[Paper]](https://arxiv.org/pdf/2209.05253.pdf)
- (arXiv 2022.11) QuadFormer: Quadruple Transformer for Unsupervised Domain Adaptation in Power Line Segmentation of Aerial Images, [[Paper]](https://arxiv.org/pdf/2211.16988.pdf)
- (arXiv 2023.03) Patch-Mix Transformer for Unsupervised Domain Adaptation: A Game Perspective, [[Paper]](https://arxiv.org/pdf/2303.13434.pdf)
- (arXiv 2023.05) Transfer Learning for Fine-grained Classification Using Semi-supervised Learning and Visual Transformers, [[Paper]](https://arxiv.org/pdf/2305.10018.pdf)
- (arXiv 2023.07) Domain Generalisation with Bidirectional Encoder Representations from Vision Transformers, [[Paper]](https://arxiv.org/pdf/2307.08117.pdf)
- (arXiv 2023.08) Domain-Specificity Inducing Transformers for Source-Free Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2308.14023.pdf), [[Code]](http://val.cds.iisc.ac.in/DSiT-SFDA/)
- (arXiv 2023.08) Transfer Learning for Microstructure Segmentation with CS-UNet: A Hybrid Algorithm with Transformer and CNN Encoders, [[Paper]](https://arxiv.org/pdf/2308.13917.pdf)
- (arXiv 2023.09) Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images, [[Paper]](https://arxiv.org/pdf/2309.02556.pdf)
- (arXiv 2023.09) Disentangling Spatial and Temporal Learning for Efficient Image-to-Video Transfer Learning, [[Paper]](https://arxiv.org/pdf/2309.07911.pdf), [[Code]](https://github.com/alibaba-mmai-research/DiST)
- (arXiv 2023.10) ZeroI2V: Zero-Cost Adaptation of Pre-trained Transformers from Image to Video, [[Paper]](https://arxiv.org/pdf/2310.01324.pdf)
- (arXiv 2023.10) Mean Teacher DETR with Masked Feature Alignment: A Robust Domain Adaptive Detection Transformer Framework, [[Paper]](https://arxiv.org/pdf/2310.15646.pdf)
- (arXiv 2023.11) Improving Source-Free Target Adaptation with Vision Transformers Leveraging Domain Representation Images, [[Paper]](https://arxiv.org/pdf/2311.12589.pdf)
- (arXiv 2024.01) Efficient Fine-Tuning with Domain Adaptation for Privacy-Preserving Vision Transformer, [[Paper]](https://arxiv.org/pdf/2401.05126.pdf)
- (arXiv 2024.01) BlenDA: Domain Adaptive Object Detection through diffusion-based blending, [[Paper]](https://arxiv.org/pdf/2401.09921.pdf), [[Code]](https://github.com/aiiu-lab/BlenDA)
- (arXiv 2024.03) Learning CNN on ViT: A Hybrid Model to Explicitly Class-specific Boundaries for Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2403.18360.pdf), [[Code]](https://dotrannhattuong.github.io/ECB/website/)
- (arXiv 2024.04) Vision Transformers in Domain Adaptation and Generalization: A Study of Robustness, [[Paper]](https://arxiv.org/pdf/2404.04452.pdf)
- (arXiv 2024.04) Vision Transformer-based Adversarial Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2404.15817.pdf), [[Code]](https://github.com/LluckyYH/VT-ADA)
- (arXiv 2024.05) DATR: Unsupervised Domain Adaptive Detection Transformer with Dataset-Level Adaptation and Prototypical Alignment, [[Paper]](https://arxiv.org/pdf/2405.11765.pdf), [[Code]](https://github.com/h751410234/DATR)
- (arXiv 2024.06) ExPLoRA: Parameter-Efficient Extended Pre-Training to Adapt Vision Transformers under Domain Shifts, [[Paper]](https://arxiv.org/pdf/2406.10973.pdf)
- (arXiv 2024.07) Transfer Learning with Self-Supervised Vision Transformers for Snake Identification, [[Paper]](https://arxiv.org/pdf/2407.06178.pdf), [[Code]](https://github.com/dsgt-kaggle-clef/snakeclef-2024)
- (arXiv 2024.07) Parameter-Efficient and Memory-Efficient Tuning for Vision Transformer: A Disentangled Approach, [[Paper]](https://arxiv.org/pdf/2407.06964.pdf)
- (arXiv 2024.07) Textual Query-Driven Mask Transformer for Domain Generalized Segmentation, [[Paper]](https://arxiv.org/pdf/2407.09033.pdf)
- (arXiv 2024.07) Domain Generalized Recaptured Screen Image Identification Using SWIN Transformer, [[Paper]](https://arxiv.org/pdf/2407.17170.pdf)
- (arXiv 2024.08) Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning, [[Paper]](https://arxiv.org/pdf/2408.08670.pdf)
- (arXiv 2024.09) iConFormer: Dynamic Parameter-Efficient Tuning with Input-Conditioned Adaptation, [[Paper]](https://arxiv.org/pdf/2409.02838.pdf)
- (arXiv 2024.10) Advanced Arabic Alphabet Sign Language Recognition Using Transfer Learning and Transformer Models, [[Paper]](https://arxiv.org/pdf/2410.00681.pdf)
- (arXiv 2024.11) Feature Fusion Transferability Aware Transformer for Unsupervised Domain Adaptation, [[Paper]](https://arxiv.org/pdf/2411.07794.pdf)
