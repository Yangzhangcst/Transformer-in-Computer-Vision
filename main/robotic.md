### Robotic
- (arXiv 2022.01) Look Closer: Bridging Egocentric and Third-Person Views with Transformers for Robotic Manipulation, [[Paper]](https://arxiv.org/pdf/2201.07779.pdf), [[Code]](https://github.com/jangirrishabh/look-closer)
- (arXiv 2022.02) When Transformer Meets Robotic Grasping: Exploits Context for Efficient Grasp Detection, [[Paper]](https://arxiv.org/pdf/2202.11911.pdf), [[Code]](https://github.com/WangShaoSUN/grasp-transformer)
- (arXiv 2022.07) 3D Part Assembly Generation with Instance Encoded Transformer, [[Paper]](https://arxiv.org/pdf/2207.01779.pdf)
- (arXiv 2022.09) Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation, [[Paper]](https://arxiv.org/pdf/2209.05451.pdf), [[Project]](https://peract.github.io/)
- (arXiv 2022.09) PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training, [[Paper]](https://arxiv.org/pdf/2209.11133.pdf)
- (arXiv 2022.12) RT-1: Robotics Transformer for Real-World Control at Scale, [[Paper]](https://arxiv.org/pdf/2212.06817.pdf), [[Project]](http://robotics-transformer.github.io/)
- (arXiv 2023.06) RVT: Robotic View Transformer for 3D Object Manipulation, [[Paper]](https://arxiv.org/pdf/2306.14896.pdf), [[Project]](https://robotic-view-transformer.github.io/)
- (arXiv 2023.09) AnyOKP: One-Shot and Instance-Aware Object Keypoint Extraction with Pretrained ViT, [[Paper]](https://arxiv.org/pdf/2309.08134.pdf)
- (arXiv 2023.09) PolarNet: 3D Point Clouds for Language-Guided Robotic Manipulation, [[Paper]](https://arxiv.org/pdf/2309.15596.pdf), [[Project]](https://www.di.ens.fr/willow/research/polarnet/)
- (arXiv 2023.10) Knolling bot: A Transformer-based Approach to Organizing a Messy Table, [[Paper]](https://arxiv.org/pdf/2310.04566.pdf)
- (arXiv 2023.11) M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place, [[Paper]](https://arxiv.org/pdf/2311.00926.pdf), [[Project]](https://m2-t2.github.io/)
- (arXiv 2023.11) FViT-Grasp: Grasping Objects With Using Fast Vision Transformers, [[Paper]](https://arxiv.org/pdf/2311.13986.pdf)
- (arXiv 2024.01) MResT: Multi-Resolution Sensing for Real-Time Control with Vision-Language Models, [[Paper]](https://arxiv.org/pdf/2401.14502.pdf), [[Code]](http://tinyurl.com/multi-res-realtime-control)
- (arXiv 2024.02) EffLoc: Lightweight Vision Transformer for Efficient 6-DOF Camera Relocalization, [[Paper]](https://arxiv.org/pdf/2402.13537.pdf)
- (arXiv 2024.05) Track2Act: Predicting Point Tracks from Internet Videos enables Diverse Zero-shot Robot Manipulation, [[Paper]](https://arxiv.org/pdf/2405.01527.pdf), [[Project]](https://homangab.github.io/track2act/)
- (arXiv 2024.06) Adapting Pretrained ViTs with Convolution Injector for Visuo-Motor Control, [[Paper]](https://arxiv.org/pdf/2406.06072.pdf), [[Project]](https://github.com/dojeon-ai/CoIn)
- (arXiv 2024.11) HiMemFormer: Hierarchical Memory-Aware Transformer for Multi-Agent Action Anticipation, [[Paper]](https://arxiv.org/pdf/2411.01455.pdf)
