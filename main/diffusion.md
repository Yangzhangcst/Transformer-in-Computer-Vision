### Diffusion
- (arXiv 2022.12) Scalable Diffusion Models with Transformers, [[Paper]](https://arxiv.org/pdf/2212.09748.pdf), [[Code]](https://www.wpeebles.com/DiT)
- (arXiv 2023.03) Masked Diffusion Transformer is a Strong Image Synthesizer, [[Paper]](https://arxiv.org/pdf/2303.14389.pdf), [[Code]](https://github.com/sail-sg/MDT)
- (arXiv 2023.04) ViT-DAE: Transformer-driven Diffusion Autoencoder for Histopathology Image Analysis, [[Paper]](https://arxiv.org/pdf/2304.01053.pdf)
- (arXiv 2023.06) DFormer: Diffusion-guided Transformer for Universal Image Segmentation, [[Paper]](https://arxiv.org/pdf/2306.03437.pdf), [[Code]](https://github.com/cp3wan/DFormer)
- (arXiv 2023.08) Unaligned 2D to 3D Translation with Conditional Vector-Quantized Code Diffusion using Transformers, [[Paper]](https://arxiv.org/pdf/2308.14152.pdf)
- (arXiv 2023.09) Large-Vocabulary 3D Diffusion Model with Transformer, [[Paper]](https://arxiv.org/pdf/2309.07920.pdf), [[Project]](https://ziangcao0312.github.io/difftf_pages/)
- (arXiv 2023.09) Cartoondiff: Training-free Cartoon Image Generation with Diffusion Transformer Models, [[Paper]](https://arxiv.org/pdf/2309.08251.pdf), [[Project]](https://cartoondiff.github.io/)
- (arXiv 2023.12) DiffiT: Diffusion Vision Transformers for Image Generation, [[Paper]](https://arxiv.org/pdf/2312.02139.pdf)
- (arXiv 2023.12) DiT-Head: High-Resolution Talking Head Synthesis using Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2312.06400.pdf)
- (arXiv 2024.01) SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers, [[Paper]](https://arxiv.org/pdf/2401.08740.pdf), [[Code]](https://github.com/willisma/SiT)
- (arXiv 2024.01) Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2401.11605.pdf), [[Code]](https://crowsonkb.github.io/hourglass-diffusion-transformers)
- (arXiv 2024.02) Cross-view Masked Diffusion Transformers for Person Image Synthesis, [[Paper]](https://arxiv.org/pdf/2402.01516.pdf)
- (arXiv 2024.02) FiT: Flexible Vision Transformer for Diffusion Model, [[Paper]](https://arxiv.org/pdf/2402.12376.pdf), [[Code]](https://github.com/whlzy/FiT)
- (arXiv 2024.03) Switch Diffusion Transformer: Synergizing Denoising Tasks with Sparse Mixture-of-Experts, [[Paper]](https://arxiv.org/pdf/2403.09176.pdf), [[Code]](https://byeongjun-park.github.io/Switch-DiT/)
- (arXiv 2024.03) SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2403.17004.pdf)
- (arXiv 2024.04) WcDT: World-centric Diffusion Transformer for Traffic Scene Generation, [[Paper]](https://arxiv.org/pdf/2404.02082.pdf)
- (arXiv 2024.04) Solving Masked Jigsaw Puzzles with Diffusion Vision Transformers, [[Paper]](https://arxiv.org/pdf/2404.07292.pdf)
- (arXiv 2024.04) Diffscaler: Enhancing the Generative Prowess of Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2404.09976.pdf)
- (arXiv 2024.04) Lazy Diffusion Transformer for Interactive Image Editing, [[Paper]](https://arxiv.org/pdf/2404.12382.pdf), [[Project]](https://lazydiffusion.github.io/)
- (arXiv 2024.05) U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.02730.pdf), [[Code]](https://github.com/YuchuanTian/U-DiT)
- (arXiv 2024.05) Inf-DiT: Upsampling Any-Resolution Image with Memory-Efficient Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2405.04312.pdf), [[Code]](https://github.com/THUDM/Inf-DiT)
- (arXiv 2024.05) Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.05945.pdf), [[Code]](https://github.com/THUDM/Inf-DiT)
- (arXiv 2024.05) DiffTF++: 3D-aware Diffusion Transformer for Large-Vocabulary 3D Generation, [[Paper]](https://arxiv.org/pdf/2405.08055.pdf)
- (arXiv 2024.05) Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding, [[Paper]](https://arxiv.org/pdf/2405.08748.pdf),[[Code]](http://github.com/Tencent/HunyuanDiT)
- (arXiv 2024.05) Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2405.14832.pdf),[[Project]](https://nju-3dv.github.io/projects/Direct3D/)
- (arXiv 2024.05) PipeFusion: Displaced Patch Pipeline Parallelism for Inference of Diffusion Transformer Models, [[Paper]](https://arxiv.org/pdf/2405.14430.pdf),[[Code]](https://github.com/PipeFusion/PipeFusion)
- (arXiv 2024.05) Human4DiT: Free-view Human Video Generation with 4D Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2405.17405.pdf),[[Code]](https://human4dit.github.io/)
- (arXiv 2024.05) PTQ4DiT: Post-training Quantization for Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.16005.pdf)
- (arXiv 2024.05) VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2405.18326.pdf),[[Code]](https://zhengjun-ai.github.io/viton-dit-page/)
- (arXiv 2024.05) DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention, [[Paper]](https://arxiv.org/pdf/2405.18428.pdf),[[Code]](https://github.com/hustvl/DiG)
- (arXiv 2024.06) Δ-DiT: A Training-Free Acceleration Method Tailored for Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2406.01125)
- (arXiv 2024.06) Dimba: Transformer-Mamba Diffusion Models, [[Paper]](https://arxiv.org/pdf/2406.01159),[[Code]](https://dimba-project.github.io/)
- (arXiv 2024.06) AV-DiT: Efficient Audio-Visual Diffusion Transformer for Joint Audio and Video Generation, [[Paper]](https://arxiv.org/pdf/2406.07686)
- (arXiv 2024.06) DiTFastAttn: Attention Compression for Diffusion Transformer Models, [[Paper]](https://arxiv.org/pdf/2406.08552),[[Code]](https://github.com/thu-nics/DiTFastAttn)
- (arXiv 2024.06) Lumina-Next: Making Lumina-T2X Stronger and Faster with Next-DiT, [[Paper]](https://arxiv.org/pdf/2406.18583),[[Code]](https://github.com/Alpha-VLLM/Lumina-T2X)
- (arXiv 2024.07) FORA: Fast-Forward Caching in Diffusion Transformer Acceleration, [[Paper]](https://arxiv.org/pdf/2407.01425),[[Code]](https://github.com/prathebaselva/FORA)
- (arXiv 2024.07) VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control, [[Paper]](https://arxiv.org/pdf/2407.12781)
- (arXiv 2024.07) Scaling Diffusion Transformers to 16 Billion Parameters, [[Paper]](https://arxiv.org/pdf/2407.11633),[[Code]](https://github.com/feizc/DiT-MoE)
- (arXiv 2024.07) DriveDiTFit: Fine-tuning Diffusion Transformers for Autonomous Driving, [[Paper]](https://arxiv.org/pdf/2407.15661),[[Code]](https://github.com/TtuHamg/DriveDiTFit)
- (arXiv 2024.07) Diffusion Feedback Helps CLIP See Better, [[Paper]](https://arxiv.org/pdf/2407.20171),[[Code]](https://github.com/baaivision/DIVA)
- (arXiv 2024.08) Tora: Trajectory-oriented Diffusion Transformer for Video Generation, [[Paper]](https://arxiv.org/pdf/2407.21705),[[Code]](https://github.com/ali-videoai/Tora)
- (arXiv 2024.08) Latent Space Disentanglement in Diffusion Transformers Enables Zero-shot Fine-grained Semantic Editing, [[Paper]](https://arxiv.org/pdf/2408.13335)
- (arXiv 2024.08) DiffSurf: A Transformer-based Diffusion Model for Generating and Reconstructing 3D Surfaces in Pose, [[Paper]](https://arxiv.org/pdf/2408.14860)
- (arXiv 2024.08) MegActor-Σ: Unlocking Flexible Mixed-Modal Control in Portrait Animation with Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2408.14975)
- (arXiv 2024.09) Qihoo-T2X: An Efficiency-Focused Diffusion Transformer via Proxy Tokens for Text-to-Any-Task, [[Paper]](https://arxiv.org/pdf/2409.04005),[[Code]](https://github.com/360CVGroup/Qihoo-T2X)
- (arXiv 2024.09) DiTAS: Quantizing Diffusion Transformers via Enhanced Activation Smoothing, [[Paper]](https://arxiv.org/pdf/2409.07756)
- (arXiv 2024.09) Token Caching for Diffusion Transformer Acceleration, [[Paper]](https://arxiv.org/pdf/2409.18523)
- (arXiv 2024.10) ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2410.00086),[[Code]](https://github.com/modelscope/scepter)
- (arXiv 2024.10) HarmoniCa: Harmonizing Training and Inference for Better Feature Cache in Diffusion Transformer Acceleration, [[Paper]](https://arxiv.org/pdf/2410.01723)
- (arXiv 2024.10) EC-DIT: Scaling Diffusion Transformers with Adaptive Expert-Choice Routing, [[Paper]](https://arxiv.org/pdf/2410.02098)
- (arXiv 2024.10) MDSGen: Fast and Efficient Masked Diffusion Temporal-Aware Transformers for Open-Domain Sound Generation, [[Paper]](https://arxiv.org/pdf/2410.02130)
- (arXiv 2024.10) Dynamic Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2410.03456),[[Code]](https://github.com/NUS-HPC-AI-Lab/Dynamic-Diffusion-Transformer)
- (arXiv 2024.10) SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2410.10629)
- (arXiv 2024.10) Boosting Camera Motion Control for Video Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2410.10802)
- (arXiv 2024.10) The Ingredients for Robotic Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2410.10088),[[Code]](https://github.com/sudeepdasari/dit-policy)
- (arXiv 2024.10) FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification, [[Paper]](https://arxiv.org/pdf/2410.10356)
- (arXiv 2024.10) Precipitation Nowcasting Using Diffusion Transformer with Causal Attention, [[Paper]](https://arxiv.org/pdf/2410.13314)
- (arXiv 2024.10) Group Diffusion Transformers are Unsupervised Multitask Learners, [[Paper]](https://arxiv.org/pdf/2410.15027)
- (arXiv 2024.10) Diffusion Transformer Policy, [[Paper]](https://arxiv.org/pdf/2410.15959)
- (arXiv 2024.10) On Inductive Biases That Enable Generalization of Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2410.21273)
- (arXiv 2024.10) GrounDiT: Grounding Diffusion Transformers via Noisy Patch Transplantation, [[Paper]](https://arxiv.org/pdf/2410.20474),[[Code]](https://github.com/KAIST-Visual-AI-Group/GrounDiT/)
- (arXiv 2024.10) EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching, [[Paper]](https://arxiv.org/pdf/2410.23788),[[Code]](https://github.com/xinwangChen/EDT)
- (arXiv 2024.10) In-Context LoRA for Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2410.23775),[[Code]](https://github.com/ali-vilab/In-Context-LoRA)
- (arXiv 2024.11) Learning Where to Edit Vision Transformers, [[Paper]](https://arxiv.org/pdf/2411.01948),[[Code]](https://github.com/hustyyq/Where-to-Edit)
- (arXiv 2024.11) Adaptive Caching for Faster Video Generation with Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2411.02397),[[Code]](https://github.com/AdaCache-DiT/AdaCache)
- (arXiv 2024.11) DiT4Edit: Diffusion Transformer for Image Editing, [[Paper]](https://arxiv.org/pdf/2411.03286)
- (arXiv 2024.11) DanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for Audio-Driven Dance Motion Reconstruction, [[Paper]](https://arxiv.org/pdf/2411.04646),[[Code]](https://th-mlab.github.io/DanceFusion/)
- (arXiv 2024.11) DiT4Edit: Diffusion Transformer for Image Editing, [[Paper]](https://arxiv.org/pdf/2411.03286),[[Code]](https://github.com/fkyyyy/DiT4Edit)
- (arXiv 2024.11) Latent Space Disentanglement in Diffusion Transformers Enables Precise Zero-shot Semantic Editing, [[Paper]](https://arxiv.org/pdf/2411.08196)
- (arXiv 2024.11) LaVin-DiT: Large Vision Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2411.11505)
- (arXiv 2024.11) FitDiT: Advancing the Authentic Garment Details for High-fidelity Virtual Try-on, [[Paper]](https://arxiv.org/pdf/2411.10499),[[Code]](https://github.com/BoyuanJiang/FitDiT)
- (arXiv 2024.11) Unveiling Redundancy in Diffusion Transformers (DiTs): A Systematic Study, [[Paper]](https://arxiv.org/pdf/2411.13588),[[Code]](https://github.com/xdit-project/DiTCacheAnalysis)
- (arXiv 2024.11) Accelerating Vision Diffusion Transformers with Skip Branches, [[Paper]](https://arxiv.org/pdf/2411.17616),[[Code]](https://github.com/OpenSparseLLMs/Skip-DiT)
- (arXiv 2024.11) Towards Precise Scaling Laws for Video Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2411.17470)
- (arXiv 2024.11) On Statistical Rates of Conditional Diffusion Transformers: Approximation, Estimation and Minimax Optimality, [[Paper]](https://arxiv.org/pdf/2411.17522)
- (arXiv 2024.11) LetsTalk: Latent Diffusion Transformer for Talking Video Synthesis, [[Paper]](https://arxiv.org/pdf/2411.16748),[[Code]](https://github.com/zhang-haojie/letstalk)
- (arXiv 2024.12) TinyFusion: Diffusion Transformers Learned Shallow, [[Paper]](https://arxiv.org/pdf/2412.01199),[[Code]](https://github.com/VainF/TinyFusion)
- (arXiv 2024.12) CPA: Camera-pose-awareness Diffusion Transformer for Video Generation, [[Paper]](https://arxiv.org/pdf/2412.01429)
- (arXiv 2024.12) Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks, [[Paper]](https://arxiv.org/pdf/2412.00733),[[Code]](https://github.com/fudan-generative-vision/hallo3)
- (arXiv 2024.12) OmniFlow: Any-to-Any Generation with Multi-Modal Rectified Flows, [[Paper]](https://arxiv.org/pdf/2412.01169),[[Code]](https://github.com/jacklishufan/OmniFlows)
- (arXiv 2024.12) ACDiT: Interpolating Autoregressive Conditional Modeling and Diffusion Transformer, [[Paper]](https://arxiv.org/pdf/2412.07720)
- (arXiv 2024.12) UniReal: Universal Image Generation and Editing via Learning Real-world Dynamics, [[Paper]](https://arxiv.org/pdf/2412.07774),[[Code]](https://xavierchen34.github.io/UniReal-Page/)
- (arXiv 2024.12) Video Motion Transfer with Diffusion Transformers, [[Paper]](https://arxiv.org/pdf/2412.07776),[[Code]](https://github.com/ditflow/ditflow)
